import re
import pandas as pd
import streamlit as st
import openai

from langchain.vectorstores import DocArrayInMemorySearch
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import TokenTextSplitter
from langchain.document_loaders import DataFrameLoader
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.schema import Document
from langchain_core.retrievers import BaseRetriever
from langchain.retrievers import BM25Retriever
from langchain.prompts import PromptTemplate

# üîê –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI –∫–ª—é—á–µ–π
openai.api_key = st.secrets["OPENAI_API_KEY"]
openai.organization = st.secrets.get("OPENAI_ORG_ID")  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ

# üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df = pd.read_csv("meeting_summaries.csv").dropna(subset=["–°–≤–æ–¥–∫–∞"])
df["metadata"] = df.apply(lambda row: {
    "doc_id": str(row["–î–æ–∫—É–º–µ–Ω—Ç"]),
    "date": str(row["–î–∞—Ç–∞"])
}, axis=1)

df["text"] = (
    "–î–∞—Ç–∞: " + df["–î–∞—Ç–∞"] +
    "\n–î–æ–∫—É–º–µ–Ω—Ç ‚Ññ: " + df["–î–æ–∫—É–º–µ–Ω—Ç"].astype(str) +
    "\n\n" + df["–°–≤–æ–¥–∫–∞"]
)

docs = [Document(page_content=row["text"], metadata=row["metadata"]) for _, row in df.iterrows()]

# ‚úÇÔ∏è –°–ø–ª–∏—Ç—Ç–µ—Ä —Ç–æ–∫–µ–Ω–æ–≤
splitter = TokenTextSplitter(chunk_size=400, chunk_overlap=40)
split_docs = splitter.split_documents(docs)

# üîç –≠–º–±–µ–¥–¥–∏–Ω–≥–∏
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=st.secrets["OPENAI_API_KEY"]
)

# üìö –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
vectorstore = DocArrayInMemorySearch.from_documents(split_docs, embeddings)

# üîé BM25
bm25_retriever = BM25Retriever.from_documents(split_docs)
bm25_retriever.k = 4

# üîÅ –ì–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ—Ç—Ä–∏–≤–µ—Ä
def hybrid_retrieve(query: str, vectorstore, bm25_retriever, k=4):
    vector_docs = vectorstore.similarity_search(query, k=k)
    bm25_docs = bm25_retriever.get_relevant_documents(query)

    all_docs = vector_docs + bm25_docs
    unique = {}
    for doc in all_docs:
        key = doc.page_content[:200]
        if key not in unique:
            unique[key] = doc

    return list(unique.values())[:k]

# üìÜ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã –∏ –Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
def extract_date_and_doc_id(query: str):
    date_match = re.search(r"(\d{2}\.\d{2}\.\d{4})", query)
    doc_match = re.search(r"(–¥–æ–∫—É–º–µ–Ω—Ç|–≤—Å—Ç—Ä–µ—á–∞)\s*‚Ññ?\s*(\d+)", query.lower())
    date = date_match.group(1) if date_match else None
    doc_id = doc_match.group(2) if doc_match else None
    return date, doc_id

# üß† –ö–∞—Å—Ç–æ–º–Ω—ã–π —Ä–µ—Ç—Ä–∏–≤–µ—Ä —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
class CustomRetriever(BaseRetriever):
    def get_relevant_documents(self, query: str):
        date, doc_id = extract_date_and_doc_id(query)

        filtered_docs = split_docs
        if date or doc_id:
            filtered_docs = [
                doc for doc in split_docs
                if (not date or doc.metadata.get("date") == date)
                and (not doc_id or doc.metadata.get("doc_id") == doc_id)
            ]
            if not filtered_docs:
                print("‚ö†Ô∏è –ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å –∫–æ—Ä–ø—É—Å.")
                filtered_docs = split_docs

            temp_vectorstore = DocArrayInMemorySearch.from_documents(filtered_docs, embeddings)
            temp_bm25 = BM25Retriever.from_documents(filtered_docs)
            temp_bm25.k = 4

            return hybrid_retrieve(query, temp_vectorstore, temp_bm25, k=4)

        return hybrid_retrieve(query, vectorstore, bm25_retriever, k=4)

# üìú –ü—Ä–æ–º–ø—Ç –¥–ª—è —Ü–µ–ø–æ—á–∫–∏
QA_PROMPT = PromptTemplate(
    input_variables=["context", "question"],
    template="""
–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π —Å—Ç–µ–Ω–æ–≥—Ä–∞–º–º—ã –≤—Å—Ç—Ä–µ—á.
–û—Ç–≤–µ—Ç—å **–ø–æ–ª–Ω–æ –∏ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ**, –∏—Å–ø–æ–ª—å–∑—É—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å—Ç—Ä–µ—á, –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
–û—Ç–≤–µ—á–∞–π –¥–µ—Ç–∞–ª—å–Ω–æ –∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ, —É–ø–æ–º–∏–Ω–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ª—é–¥–µ–π.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å:
{question}

–û—Ç–≤–µ—Ç:
"""
)

# üîß –°–±–æ—Ä–∫–∞ —Ü–µ–ø–æ—á–∫–∏ RAG
def build_rag_chain():
    llm = ChatOpenAI(
        model_name="gpt-4",
        temperature=0.2,
        max_tokens=2048,
        openai_api_key=st.secrets["OPENAI_API_KEY"]
    )

    retriever = CustomRetriever()

    return RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",
        chain_type_kwargs={"prompt": QA_PROMPT},
        return_source_documents=True
    )
